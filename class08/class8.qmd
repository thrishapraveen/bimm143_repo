---
title: "class8"
author: Thrisha Praveen
format: pdf
---

```{r}
head(mtcars)
```

```{r}
apply(mtcars, 2, mean)
```

It is clear "disp" and "hp" have the highest mean values and the highest standard deviation here. They will likely dominate any analysis I do on this dataset. Let's see.

```{r}
pc.noscale <- prcomp(mtcars, scale=FALSE)
pc.scale <- prcomp(mtcars, scale=TRUE)
```

```{r}
pc.noscale$rotation[,1]
```

plot the loadings

```{r}
library(ggplot2)
r2 <- as.data.frame(pc.noscale$rotation) 
r2$names <- rownames(pc.noscale$rotation)
ggplot(r2)+aes(PC1, names)+geom_col()
```

```{r}
biplot(pc.scale)
```

> **Take home**: Generally we always want to set `scale=TRUE` when we do this type of analysis to avoid our analysis being dominated by individual variables with the largest variance just due to their unit of mesurement. 

#FNA breast cancer data

Load the data into R. 

```{r}
# Save your input data file into your Project directory
fna.data <- "WisconsinCancer.csv"

# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data, row.names=1)

head(wisc.df)
```
> Q1. How many observations are in this dataset? 
**569 observations/rows**

```{r}
nrow(wisc.df)
```

> Q2. How many of the observations have a malignant diagnosis?

```{r}
#sums how many observations have M/malignant diagnosis 
sum(wisc.df$diagnosis == "M")
```
The `table()` function is useful here
```{r}
table(wisc.df$diagnosis)
```


> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
ncol(wisc.df)
colnames(wisc.df)
```
A useful function for this is `grep()` 
```{r}
#searches for pattern in column names and counts how many have pattern of "_mean"
length(grep("_mean", colnames(wisc.df)))
```

Before going further, need to exclude diagnosis column from any future analysis - this tells us whether a sample to cancer or non-cancer 
```{r}
#stored as a factor - object type, used for stats & plots
diagnosis <- as.factor(wisc.df$diagnosis)
head(diagnosis)
```

```{r}
wisc.data <- wisc.df[,-1]
head(wisc.data)
```

Let's see if we can cluster the `wisc.data` to find some structure in the dataset. 

```{r}
hc <- hclust(dist(wisc.data))
plot(hc)
```

#principal component analysis (PCA)

```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp( wisc.data, scale=T )
summary(wisc.pr)
```
>Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

0.4427 is the proportion of the original variance that is captured by PC1.

>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

We needed 3 PCs to describe at least 70% of the original variance in the data (based on the cumulative proportion values from my results).

>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

We needed 7 PCs to describe at least 70% of the original variance in the data (based on the cumulative proportion values from my results).



```{r}
biplot(wisc.pr)
```
This biplot sucks! We need to build our own PCA score plot of PC1 vs. PC2.

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

It's very difficult to understand since all of the patient ID's and column names overlap. It's not easy to read or interpret. 

```{r}
attributes(wisc.pr)

head(wisc.pr$x)
```

plot of PC1 vs PC2 the 1st 2 columns
```{r}
plot(wisc.pr$x[,1],wisc.pr$x[,2], col=diagnosis,xlab = "PC1", ylab = "PC2")
```
> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

The benign group is lower on the PC3 axis on this plot than it was for PC2.

```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[,1],wisc.pr$x[,3], col=diagnosis,xlab = "PC1", ylab = "PC3")
```

```{r}
pc <- as.data.frame(wisc.pr$x)

ggplot(pc)+
  aes(PC1,PC2,col=diagnosis)+
  geom_point()
```

##Variance explained
```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
## ggplot based graph
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```
>Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

 -0.26085376, based on the results below:
```{r}
wisc.pr$rotation["concave.points_mean",1]
```

>Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

5 is the minimum number of principal components required to explain 80% of the variance of the data.

##Hierarchical clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
```

>Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

The height should be at y=19 since that is where there is 4 distinct clusters.

```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

##Selecting number of clusters
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, 4)
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

Maybe 8 clusters to show which cluster is obviously more malignant than benign and vice versa. However, all are not great.

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, 8)
table(wisc.hclust.clusters, diagnosis)
```

##Using different methods
```{r}
wisc.hclust <- hclust(data.dist, method = "ward.D2")
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

>Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

ward.D2 since it more clearly shows the clustering since the lines aren't overlapping as much.

#Combining methods
##cultering on PCA results

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:2]), method = "ward.D2")
plot(wisc.pr.hclust)
abline(h=70, col="red")

```
Cluster membership vector

```{r}
grps <- cutree(wisc.pr.hclust, h=70)
table(grps)
```

Cross-table to see how my clustering groups correspond to the expert diagnosis vector of M and B values.
```{r}
table(grps, diagnosis)
```

Positive would be malignant/cancer/"M"
Negative would be benign/non-cancer/"B"

True = cluster/grp 1
False = grp 2

true positive (grp 1 & M) = 177 / 212
false positive (grp 1 & B) = 18

true negative (grp 2 & B) = 339
false negative (grp 2 & M) = 35

We can use our PCA results (wisc.pr) to make predictions on new unseen data. 

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)

plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

5. Combining methods
Clustering on PCA results:
(these are different from that on the worksheet, but i dont know why, everything else has been the same)
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
table(grps, diagnosis)
```
This plot is also slightly different than what is on the worksheet, and I'm unsure why.
```{r}
plot(wisc.pr$x[,1:2], col=grps)

```
```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)

```

OPTIONAL: Note the color swap here as the hclust cluster 1 is mostly “M” and cluster 2 is mostly “B” as we saw from the results of calling table(grps, diagnosis). To match things up we can turn our groups into a factor and reorder the levels so cluster 2 comes first and thus gets the first color (black) and cluster 1 gets the second color (red).

```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```

```{r}
# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method="ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)

table(wisc.pr.hclust.clusters)
table(wisc.pr.hclust.clusters, diagnosis)

```

>Q15. How well does the newly created model with four clusters separate out the two diagnoses?

Each cluster has majority of only one diagnosis, so the newly created model is good at separating out the two diagnoses.

>Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

Didn't work for me since I didn't understand how to do the K-means clustering section, so I don't have a wisc.km object.
```{r}
#table(wisc.km$cluster, diagnosis)
#table(wisc.hclust.clusters, diagnosis)
```

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Sensitivity refers to a test’s ability to correctly detect ill patients who do have the condition. In our example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

Specificity relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).

- Combining methods (the last analysis procedure) gave me a better sensitivity (0.886) and a better sensitivity (0.932).

7. Prediction

We will use the predict() function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.
```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc

```
```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

>Q18. Which of these new patients should we prioritize for follow up based on your results?

Probably Patient 2 since they are in the malignant clump/cluster based on what was generated from the previous data set.